{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbb7c44ca98d446e898d6e98bc626e909",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import rrsBdtDevDependencies\n",
    "import dataFunctions as dataFun\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import quandl\n",
    "QAPIKEY = \"YpAydSEsKoSAfuQ9UKhu\"\n",
    "quandl.ApiConfig.api_key = QAPIKEY\n",
    "import yfinance as yf\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGURE ###\n",
    "barrels = 750000\n",
    "costPerDay = 30000\n",
    "daysToPredict = 1\n",
    "trainDataDate = '2018-01-01'\n",
    "testSplitDate = '2020-01-01'\n",
    "\n",
    "params = {\n",
    "    \"batch_size\": 20,  # 20<16<10, 25 was a bust\n",
    "    \"epochs\": 300,\n",
    "    \"lr\": 0.00010000,\n",
    "    \"time_steps\": 10\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Running...\n"
    }
   ],
   "source": [
    "print('Running...')\n",
    "\n",
    "def show_more(df, lines):\n",
    "    with pd.option_context(\"display.max_rows\", lines):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, features, label=None, shift = 0, nonShiftFeatures = None):\n",
    "    df = df.set_index('Date')\n",
    "    #X = df[['OilProduction', 'NatGasPrices', 'BrentPrices', '20dSMA', 'Momentum_14', 'MACD_12_26', 'MACDdiff_12_26', 'ROC_14', 'RSI_14', 'bollAmplitude', 'distFromTopBoll', 'distFromLowBoll', '20d200dDist','dayofyear','dayofmonth','weekofyear']]\n",
    "\n",
    "    # X = df[['OilProduction', '20dSMA', 'Momentum_14', 'MACD_12_26', 'MACDdiff_12_26', 'ROC_14', 'RSI_14', 'bollAmplitude', 'distFromTopBoll', 'distFromLowBoll', '20d200dDist','dayofyear','dayofmonth','weekofyear']]\n",
    "    # if shift > 0:\n",
    "    #     tiems = X[['dayofyear','dayofmonth','weekofyear']]\n",
    "    #     #X = X[['OilProduction', 'NatGasPrices', 'BrentPrices', '20dSMA', 'Momentum_14', 'MACD_12_26', 'MACDdiff_12_26','ROC_14', 'RSI_14', 'bollAmplitude', 'distFromTopBoll', 'distFromLowBoll', '20d200dDist']].shift(shift)\n",
    "    #     X = X[['OilProduction', '20dSMA', 'Momentum_14', 'MACD_12_26', 'MACDdiff_12_26','ROC_14', 'RSI_14', 'bollAmplitude', 'distFromTopBoll', 'distFromLowBoll', '20d200dDist']].shift(shift)\n",
    "    #     X = X.merge(tiems, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "    X = df[features]\n",
    "    if shift > 0:\n",
    "        tiems = X[nonShiftFeatures]\n",
    "        newFeatures = features\n",
    "        for f in nonShiftFeatures:\n",
    "            newFeatures.remove(f)\n",
    "        X = X[newFeatures].shift(shift)\n",
    "        X = X.merge(tiems, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "    if label:\n",
    "        y = df[label]\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[*********************100%***********************]  1 of 1 completed\n[*********************100%***********************]  1 of 1 completed\n[*********************100%***********************]  1 of 1 completed\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Getting WTI price data \n",
    "\"\"\"\n",
    "\n",
    "wtiData         = quandl.get(\"FRED/DCOILWTICO\")\n",
    "wtiData.reset_index(level=0, inplace=True)\n",
    "wtiData         = wtiData.rename(columns={\"Value\": \"Prices\"})\n",
    "yfStartDate     = wtiData['Date'].iloc[-1].strftime('%Y-%m-%d')\n",
    "stocks          = \"CL=F\"\n",
    "period          = \"1d\"\n",
    "Stocks, yfInfo  = dataFun.yFinData(yfStartDate)\n",
    "wtiData         = wtiData.append(Stocks, ignore_index =True)\n",
    "wtiData         = wtiData.sort_values(by = [\"Date\"])\n",
    "\n",
    "# Getting Oil production data and combining dataframes\n",
    "oilDF   = dataFun.oilProduction()\n",
    "df      = dataFun.combineFrames(wtiData,oilDF)\n",
    "df      = df[np.isfinite(df['Prices'])]\n",
    "df      = df.reset_index().drop([\"index\"], axis = 1)\n",
    "\n",
    "# Getting natural gas data and combining frames\n",
    "natGasData          = quandl.get(\"EIA/NG_RNGWHHD_D\")\n",
    "natGasData.reset_index(level=0, inplace=True)\n",
    "natGasData          = natGasData.rename(columns={\"Value\": \"NatGasPrices\"})\n",
    "yfStartDate         = natGasData['Date'].iloc[-1].strftime('%Y-%m-%d')\n",
    "stocks              = \"NG=F\"\n",
    "period              = \"1d\"\n",
    "NGStocks, yfInfo    = dataFun.yFinData(yfStartDate,stock=stocks,name =\"NatGasPrices\")\n",
    "natGasData          = natGasData.append(NGStocks, ignore_index =True)\n",
    "natGasData          = natGasData.sort_values(by = [\"Date\"])\n",
    "newdf               = pd.merge(df, natGasData, on=['Date'], how =\"left\")\n",
    "\n",
    "\"\"\"\n",
    "Getting Brent oil data and combining dataframes\n",
    "\"\"\"\n",
    "\n",
    "brentData = quandl.get(\"FRED/DCOILBRENTEU\")\n",
    "brentData.reset_index(level=0, inplace=True)\n",
    "name = \"BrentPrices\"\n",
    "brentData = brentData.rename(columns={\"Value\": name})\n",
    "yfStartDate = brentData['Date'].iloc[-1].strftime('%Y-%m-%d')\n",
    "stocks = \"BZ=F\"\n",
    "period = \"1d\"\n",
    "BStocks, yfInfo = dataFun.yFinData(yfStartDate,stock=stocks,name = name)\n",
    "brentData = brentData.append(BStocks, ignore_index =True)\n",
    "brentData = brentData.sort_values(by = [\"Date\"])\n",
    "df = pd.merge(newdf, brentData, on=['Date'], how =\"left\")\n",
    "\n",
    "df[\"BrentPrices\"] = df[\"BrentPrices\"].interpolate(method='nearest')\n",
    "df[\"NatGasPrices\"] = df[\"NatGasPrices\"].interpolate(method='nearest')\n",
    "\n",
    "# Calculating the technical indicators for price data\n",
    "df = df.reset_index().drop([\"index\"], axis = 1)\n",
    "df[\"20dSMA\"] = dataFun.SMA(20, df[\"Prices\"])\n",
    "df[\"10dSMA\"] = dataFun.SMA(10, df[\"Prices\"])\n",
    "df[\"5dSMA\"] = dataFun.SMA(5, df[\"Prices\"])\n",
    "df[\"50dSMA\"] = dataFun.SMA(50, df[\"Prices\"])\n",
    "df[\"200dSMA\"] = dataFun.SMA(200, df[\"Prices\"])\n",
    "\n",
    "\n",
    "df[\"boll_lo\"] = dataFun.bollinger(df['Prices'])[0]\n",
    "df[\"boll_hi\"] = dataFun.bollinger(df['Prices'])[1]\n",
    "\n",
    "df = dataFun.momentum(df, 14)\n",
    "df = dataFun.macd(df, 12, 26)\n",
    "df = dataFun.rate_of_change(df, 14)\n",
    "df = dataFun.relative_strength_index(df)\n",
    "\n",
    "df[\"boll_hi\"] = pd.to_numeric(df[\"boll_hi\"])\n",
    "df[\"boll_lo\"] = pd.to_numeric(df[\"boll_lo\"])\n",
    "df[\"20dSMA\"] = pd.to_numeric(df[\"20dSMA\"])\n",
    "df[\"10dSMA\"] = pd.to_numeric(df[\"10dSMA\"])\n",
    "df[\"5dSMA\"] = pd.to_numeric(df[\"5dSMA\"])\n",
    "df[\"50dSMA\"] = pd.to_numeric(df[\"50dSMA\"])\n",
    "df[\"200dSMA\"] = pd.to_numeric(df[\"200dSMA\"])\n",
    "\n",
    "df[\"bollAmplitude\"] = df[\"boll_hi\"] - df[\"boll_lo\"]\n",
    "df[\"distFromTopBoll\"] = df[\"boll_hi\"] - df[\"Prices\"]\n",
    "df[\"distFromLowBoll\"] = df[\"boll_lo\"] - df[\"Prices\"]\n",
    "df[\"20d200dDist\"] = np.abs(df[\"20dSMA\"] - df[\"200dSMA\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Processing the resultant data frame\n",
    "\"\"\"\n",
    "\n",
    "df = df[df[\"Date\"] > trainDataDate]\n",
    "df = df[np.isfinite(df['200dSMA'])]\n",
    "df = df.rename(columns={\"Production of Crude Oil\": \"OilProduction\"})\n",
    "df = df.drop_duplicates(\"Date\",keep=\"first\")\n",
    "df = df.reset_index().drop([\"index\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating time series features from datetime index\n",
    "\"\"\"\n",
    "\n",
    "df['dayofweek'] = df['Date'].dt.dayofweek\n",
    "df['quarter'] = df['Date'].dt.quarter\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['dayofyear'] = df['Date'].dt.dayofyear\n",
    "df['dayofmonth'] = df['Date'].dt.day\n",
    "df['weekofyear'] = df['Date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df[\"Date\"] <= testSplitDate].copy()\n",
    "df_test = df[df[\"Date\"] > testSplitDate].copy()\n",
    "\n",
    "# df_train, df_test = train_test_split(df, train_size=0.9, test_size=0.1, shuffle=False)\n",
    "\n",
    "features = [\"Prices\"]\n",
    "# training_set = df.set_index('Date')\n",
    "# training_set = training_set[features]\n",
    "\n",
    "#['OilProduction', '20dSMA', 'Momentum_14', 'MACD_12_26', 'MACDdiff_12_26', 'ROC_14', 'RSI_14', 'bollAmplitude', 'distFromTopBoll', 'distFromLowBoll', '20d200dDist','dayofyear','dayofmonth','weekofyear']\n",
    "nonShiftFeatures = ['dayofyear','dayofmonth','weekofyear']\n",
    "\n",
    "# X_train, y_train = create_features(df_train,features,label='Prices', shift =1)\n",
    "# X_test, y_test = create_features(df_test,label='Prices', shift =1)\n",
    "# X_train = X_train.iloc[1:]\n",
    "# X_test = X_test.iloc[1:]\n",
    "# y_train = y_train.iloc[1:]\n",
    "# y_test = y_test.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.set_index('Date')\n",
    "df_test = df_test.set_index('Date')\n",
    "x = df_train.loc[:,features].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prices</th>\n      <th>OilProduction</th>\n      <th>NatGasPrices</th>\n      <th>BrentPrices</th>\n      <th>20dSMA</th>\n      <th>10dSMA</th>\n      <th>5dSMA</th>\n      <th>50dSMA</th>\n      <th>200dSMA</th>\n      <th>boll_lo</th>\n      <th>...</th>\n      <th>distFromTopBoll</th>\n      <th>distFromLowBoll</th>\n      <th>20d200dDist</th>\n      <th>dayofweek</th>\n      <th>quarter</th>\n      <th>month</th>\n      <th>year</th>\n      <th>dayofyear</th>\n      <th>dayofmonth</th>\n      <th>weekofyear</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-01-02</th>\n      <td>61.170000</td>\n      <td>12900.0</td>\n      <td>2.050</td>\n      <td>67.050000</td>\n      <td>60.2600</td>\n      <td>61.179</td>\n      <td>61.490000</td>\n      <td>57.9114</td>\n      <td>57.78580</td>\n      <td>57.978542</td>\n      <td>...</td>\n      <td>1.371458</td>\n      <td>-3.191458</td>\n      <td>2.47420</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2020-01-03</th>\n      <td>63.000000</td>\n      <td>12900.0</td>\n      <td>2.060</td>\n      <td>69.080000</td>\n      <td>60.4870</td>\n      <td>61.386</td>\n      <td>61.746000</td>\n      <td>58.1058</td>\n      <td>57.80535</td>\n      <td>58.060783</td>\n      <td>...</td>\n      <td>-0.086783</td>\n      <td>-4.939217</td>\n      <td>2.68165</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2020-01-06</th>\n      <td>63.270000</td>\n      <td>12900.0</td>\n      <td>2.100</td>\n      <td>70.250000</td>\n      <td>60.7295</td>\n      <td>61.583</td>\n      <td>62.048000</td>\n      <td>58.2870</td>\n      <td>57.82610</td>\n      <td>58.205614</td>\n      <td>...</td>\n      <td>-0.016614</td>\n      <td>-5.064386</td>\n      <td>2.90340</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2020-01-07</th>\n      <td>62.700000</td>\n      <td>12900.0</td>\n      <td>2.170</td>\n      <td>68.740000</td>\n      <td>60.9045</td>\n      <td>61.810</td>\n      <td>62.256000</td>\n      <td>58.4230</td>\n      <td>57.83900</td>\n      <td>58.342079</td>\n      <td>...</td>\n      <td>0.766921</td>\n      <td>-4.357921</td>\n      <td>3.06550</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>7</td>\n      <td>7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2020-01-08</th>\n      <td>59.650000</td>\n      <td>12900.0</td>\n      <td>2.090</td>\n      <td>67.310000</td>\n      <td>60.9375</td>\n      <td>61.724</td>\n      <td>61.958000</td>\n      <td>58.4938</td>\n      <td>57.83735</td>\n      <td>58.463416</td>\n      <td>...</td>\n      <td>3.761584</td>\n      <td>-1.186584</td>\n      <td>3.10015</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2020-01-09</th>\n      <td>59.560000</td>\n      <td>12900.0</td>\n      <td>2.090</td>\n      <td>66.580000</td>\n      <td>60.9545</td>\n      <td>61.563</td>\n      <td>61.636000</td>\n      <td>58.5546</td>\n      <td>57.84080</td>\n      <td>58.525851</td>\n      <td>...</td>\n      <td>3.823149</td>\n      <td>-1.034149</td>\n      <td>3.11370</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>9</td>\n      <td>9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2020-01-10</th>\n      <td>59.020000</td>\n      <td>13000.0</td>\n      <td>2.050</td>\n      <td>66.770000</td>\n      <td>60.9685</td>\n      <td>61.293</td>\n      <td>60.840000</td>\n      <td>58.6230</td>\n      <td>57.84235</td>\n      <td>58.590909</td>\n      <td>...</td>\n      <td>4.326091</td>\n      <td>-0.429091</td>\n      <td>3.12615</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2020-01-13</th>\n      <td>58.170000</td>\n      <td>13000.0</td>\n      <td>2.030</td>\n      <td>64.140000</td>\n      <td>60.9180</td>\n      <td>60.934</td>\n      <td>59.820000</td>\n      <td>58.6796</td>\n      <td>57.83385</td>\n      <td>58.345542</td>\n      <td>...</td>\n      <td>5.320458</td>\n      <td>0.175542</td>\n      <td>3.08415</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>13</td>\n      <td>13</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2020-01-14</th>\n      <td>58.340000</td>\n      <td>13000.0</td>\n      <td>2.150</td>\n      <td>64.450000</td>\n      <td>60.8295</td>\n      <td>60.602</td>\n      <td>58.948000</td>\n      <td>58.7494</td>\n      <td>57.82860</td>\n      <td>58.028376</td>\n      <td>...</td>\n      <td>5.290624</td>\n      <td>-0.311624</td>\n      <td>3.00090</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>14</td>\n      <td>14</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2020-01-15</th>\n      <td>57.860000</td>\n      <td>13000.0</td>\n      <td>2.010</td>\n      <td>63.290000</td>\n      <td>60.7120</td>\n      <td>60.274</td>\n      <td>58.590000</td>\n      <td>58.8262</td>\n      <td>57.82145</td>\n      <td>57.619465</td>\n      <td>...</td>\n      <td>5.944535</td>\n      <td>-0.240535</td>\n      <td>2.89055</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>15</td>\n      <td>15</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2020-01-16</th>\n      <td>58.520000</td>\n      <td>13000.0</td>\n      <td>2.060</td>\n      <td>64.630000</td>\n      <td>60.5940</td>\n      <td>60.009</td>\n      <td>58.382000</td>\n      <td>58.8758</td>\n      <td>57.81310</td>\n      <td>57.351971</td>\n      <td>...</td>\n      <td>5.316029</td>\n      <td>-1.168029</td>\n      <td>2.78090</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>16</td>\n      <td>16</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2020-01-17</th>\n      <td>58.550000</td>\n      <td>13000.0</td>\n      <td>2.070</td>\n      <td>64.050000</td>\n      <td>60.4750</td>\n      <td>59.564</td>\n      <td>58.288000</td>\n      <td>58.9202</td>\n      <td>57.79790</td>\n      <td>57.112423</td>\n      <td>...</td>\n      <td>5.287577</td>\n      <td>-1.437577</td>\n      <td>2.67710</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>17</td>\n      <td>17</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2020-01-21</th>\n      <td>58.250000</td>\n      <td>13000.0</td>\n      <td>1.980</td>\n      <td>63.660000</td>\n      <td>60.3225</td>\n      <td>59.062</td>\n      <td>58.304000</td>\n      <td>58.9444</td>\n      <td>57.77650</td>\n      <td>56.842852</td>\n      <td>...</td>\n      <td>5.552148</td>\n      <td>-1.407148</td>\n      <td>2.54600</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>21</td>\n      <td>21</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2020-01-22</th>\n      <td>56.760000</td>\n      <td>13000.0</td>\n      <td>1.890</td>\n      <td>62.110000</td>\n      <td>60.1390</td>\n      <td>58.468</td>\n      <td>57.988000</td>\n      <td>58.9566</td>\n      <td>57.74800</td>\n      <td>56.313348</td>\n      <td>...</td>\n      <td>7.204652</td>\n      <td>-0.446652</td>\n      <td>2.39100</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>22</td>\n      <td>22</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2020-01-23</th>\n      <td>55.510000</td>\n      <td>13000.0</td>\n      <td>1.950</td>\n      <td>61.260000</td>\n      <td>59.8890</td>\n      <td>58.054</td>\n      <td>57.518000</td>\n      <td>58.9286</td>\n      <td>57.71495</td>\n      <td>55.546816</td>\n      <td>...</td>\n      <td>8.721184</td>\n      <td>0.036816</td>\n      <td>2.17405</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>23</td>\n      <td>23</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2020-01-24</th>\n      <td>54.090000</td>\n      <td>13000.0</td>\n      <td>1.910</td>\n      <td>59.340000</td>\n      <td>59.5350</td>\n      <td>57.507</td>\n      <td>56.632000</td>\n      <td>58.8700</td>\n      <td>57.66990</td>\n      <td>54.528892</td>\n      <td>...</td>\n      <td>10.451108</td>\n      <td>0.438892</td>\n      <td>1.86510</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>24</td>\n      <td>24</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2020-01-27</th>\n      <td>53.090000</td>\n      <td>13000.0</td>\n      <td>2.030</td>\n      <td>58.540000</td>\n      <td>57.2935</td>\n      <td>53.653</td>\n      <td>49.002000</td>\n      <td>58.1774</td>\n      <td>57.42105</td>\n      <td>41.368229</td>\n      <td>...</td>\n      <td>20.128771</td>\n      <td>-11.721771</td>\n      <td>0.12755</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>27</td>\n      <td>27</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2020-01-28</th>\n      <td>53.820000</td>\n      <td>13000.0</td>\n      <td>1.960</td>\n      <td>59.720001</td>\n      <td>55.5875</td>\n      <td>51.611</td>\n      <td>53.188000</td>\n      <td>57.8782</td>\n      <td>57.20770</td>\n      <td>40.149164</td>\n      <td>...</td>\n      <td>17.205837</td>\n      <td>-13.670836</td>\n      <td>1.62020</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>28</td>\n      <td>28</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2020-01-29</th>\n      <td>53.099998</td>\n      <td>13000.0</td>\n      <td>1.960</td>\n      <td>59.599998</td>\n      <td>55.0790</td>\n      <td>51.096</td>\n      <td>53.190000</td>\n      <td>57.8416</td>\n      <td>57.15315</td>\n      <td>40.041356</td>\n      <td>...</td>\n      <td>17.016645</td>\n      <td>-13.058642</td>\n      <td>2.07415</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>29</td>\n      <td>29</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2020-01-30</th>\n      <td>52.849998</td>\n      <td>13000.0</td>\n      <td>1.960</td>\n      <td>59.070000</td>\n      <td>54.5865</td>\n      <td>50.705</td>\n      <td>53.142000</td>\n      <td>57.7644</td>\n      <td>57.09870</td>\n      <td>39.960218</td>\n      <td>...</td>\n      <td>16.362784</td>\n      <td>-12.889781</td>\n      <td>2.51220</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>30</td>\n      <td>30</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2020-01-31</th>\n      <td>51.630001</td>\n      <td>13000.0</td>\n      <td>1.862</td>\n      <td>58.150002</td>\n      <td>54.1855</td>\n      <td>50.317</td>\n      <td>52.874000</td>\n      <td>57.6298</td>\n      <td>57.03675</td>\n      <td>39.704700</td>\n      <td>...</td>\n      <td>17.036299</td>\n      <td>-11.925301</td>\n      <td>2.85125</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2020</td>\n      <td>31</td>\n      <td>31</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2020-02-02</th>\n      <td>51.009998</td>\n      <td>13000.0</td>\n      <td>1.862</td>\n      <td>58.150002</td>\n      <td>53.7580</td>\n      <td>50.009</td>\n      <td>52.481999</td>\n      <td>57.4964</td>\n      <td>56.96350</td>\n      <td>39.441370</td>\n      <td>...</td>\n      <td>17.064631</td>\n      <td>-11.568628</td>\n      <td>3.20550</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2020</td>\n      <td>33</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2020-02-03</th>\n      <td>49.939999</td>\n      <td>13000.0</td>\n      <td>1.829</td>\n      <td>54.220001</td>\n      <td>53.3040</td>\n      <td>52.447</td>\n      <td>51.705999</td>\n      <td>57.3394</td>\n      <td>56.88200</td>\n      <td>39.114648</td>\n      <td>...</td>\n      <td>17.553353</td>\n      <td>-10.825351</td>\n      <td>3.57800</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2020</td>\n      <td>34</td>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2020-02-04</th>\n      <td>49.680000</td>\n      <td>13000.0</td>\n      <td>1.879</td>\n      <td>53.959999</td>\n      <td>52.8795</td>\n      <td>52.106</td>\n      <td>51.021999</td>\n      <td>57.1680</td>\n      <td>56.80060</td>\n      <td>38.795500</td>\n      <td>...</td>\n      <td>17.283499</td>\n      <td>-10.884500</td>\n      <td>3.92110</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2020</td>\n      <td>35</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>24 rows Ã— 28 columns</p>\n</div>",
      "text/plain": "               Prices  OilProduction  NatGasPrices  BrentPrices   20dSMA  \\\nDate                                                                       \n2020-01-02  61.170000        12900.0         2.050    67.050000  60.2600   \n2020-01-03  63.000000        12900.0         2.060    69.080000  60.4870   \n2020-01-06  63.270000        12900.0         2.100    70.250000  60.7295   \n2020-01-07  62.700000        12900.0         2.170    68.740000  60.9045   \n2020-01-08  59.650000        12900.0         2.090    67.310000  60.9375   \n2020-01-09  59.560000        12900.0         2.090    66.580000  60.9545   \n2020-01-10  59.020000        13000.0         2.050    66.770000  60.9685   \n2020-01-13  58.170000        13000.0         2.030    64.140000  60.9180   \n2020-01-14  58.340000        13000.0         2.150    64.450000  60.8295   \n2020-01-15  57.860000        13000.0         2.010    63.290000  60.7120   \n2020-01-16  58.520000        13000.0         2.060    64.630000  60.5940   \n2020-01-17  58.550000        13000.0         2.070    64.050000  60.4750   \n2020-01-21  58.250000        13000.0         1.980    63.660000  60.3225   \n2020-01-22  56.760000        13000.0         1.890    62.110000  60.1390   \n2020-01-23  55.510000        13000.0         1.950    61.260000  59.8890   \n2020-01-24  54.090000        13000.0         1.910    59.340000  59.5350   \n2020-01-27  53.090000        13000.0         2.030    58.540000  57.2935   \n2020-01-28  53.820000        13000.0         1.960    59.720001  55.5875   \n2020-01-29  53.099998        13000.0         1.960    59.599998  55.0790   \n2020-01-30  52.849998        13000.0         1.960    59.070000  54.5865   \n2020-01-31  51.630001        13000.0         1.862    58.150002  54.1855   \n2020-02-02  51.009998        13000.0         1.862    58.150002  53.7580   \n2020-02-03  49.939999        13000.0         1.829    54.220001  53.3040   \n2020-02-04  49.680000        13000.0         1.879    53.959999  52.8795   \n\n            10dSMA      5dSMA   50dSMA   200dSMA    boll_lo  ...  \\\nDate                                                         ...   \n2020-01-02  61.179  61.490000  57.9114  57.78580  57.978542  ...   \n2020-01-03  61.386  61.746000  58.1058  57.80535  58.060783  ...   \n2020-01-06  61.583  62.048000  58.2870  57.82610  58.205614  ...   \n2020-01-07  61.810  62.256000  58.4230  57.83900  58.342079  ...   \n2020-01-08  61.724  61.958000  58.4938  57.83735  58.463416  ...   \n2020-01-09  61.563  61.636000  58.5546  57.84080  58.525851  ...   \n2020-01-10  61.293  60.840000  58.6230  57.84235  58.590909  ...   \n2020-01-13  60.934  59.820000  58.6796  57.83385  58.345542  ...   \n2020-01-14  60.602  58.948000  58.7494  57.82860  58.028376  ...   \n2020-01-15  60.274  58.590000  58.8262  57.82145  57.619465  ...   \n2020-01-16  60.009  58.382000  58.8758  57.81310  57.351971  ...   \n2020-01-17  59.564  58.288000  58.9202  57.79790  57.112423  ...   \n2020-01-21  59.062  58.304000  58.9444  57.77650  56.842852  ...   \n2020-01-22  58.468  57.988000  58.9566  57.74800  56.313348  ...   \n2020-01-23  58.054  57.518000  58.9286  57.71495  55.546816  ...   \n2020-01-24  57.507  56.632000  58.8700  57.66990  54.528892  ...   \n2020-01-27  53.653  49.002000  58.1774  57.42105  41.368229  ...   \n2020-01-28  51.611  53.188000  57.8782  57.20770  40.149164  ...   \n2020-01-29  51.096  53.190000  57.8416  57.15315  40.041356  ...   \n2020-01-30  50.705  53.142000  57.7644  57.09870  39.960218  ...   \n2020-01-31  50.317  52.874000  57.6298  57.03675  39.704700  ...   \n2020-02-02  50.009  52.481999  57.4964  56.96350  39.441370  ...   \n2020-02-03  52.447  51.705999  57.3394  56.88200  39.114648  ...   \n2020-02-04  52.106  51.021999  57.1680  56.80060  38.795500  ...   \n\n            distFromTopBoll  distFromLowBoll  20d200dDist  dayofweek  quarter  \\\nDate                                                                            \n2020-01-02         1.371458        -3.191458      2.47420          3        1   \n2020-01-03        -0.086783        -4.939217      2.68165          4        1   \n2020-01-06        -0.016614        -5.064386      2.90340          0        1   \n2020-01-07         0.766921        -4.357921      3.06550          1        1   \n2020-01-08         3.761584        -1.186584      3.10015          2        1   \n2020-01-09         3.823149        -1.034149      3.11370          3        1   \n2020-01-10         4.326091        -0.429091      3.12615          4        1   \n2020-01-13         5.320458         0.175542      3.08415          0        1   \n2020-01-14         5.290624        -0.311624      3.00090          1        1   \n2020-01-15         5.944535        -0.240535      2.89055          2        1   \n2020-01-16         5.316029        -1.168029      2.78090          3        1   \n2020-01-17         5.287577        -1.437577      2.67710          4        1   \n2020-01-21         5.552148        -1.407148      2.54600          1        1   \n2020-01-22         7.204652        -0.446652      2.39100          2        1   \n2020-01-23         8.721184         0.036816      2.17405          3        1   \n2020-01-24        10.451108         0.438892      1.86510          4        1   \n2020-01-27        20.128771       -11.721771      0.12755          0        1   \n2020-01-28        17.205837       -13.670836      1.62020          1        1   \n2020-01-29        17.016645       -13.058642      2.07415          2        1   \n2020-01-30        16.362784       -12.889781      2.51220          3        1   \n2020-01-31        17.036299       -11.925301      2.85125          4        1   \n2020-02-02        17.064631       -11.568628      3.20550          6        1   \n2020-02-03        17.553353       -10.825351      3.57800          0        1   \n2020-02-04        17.283499       -10.884500      3.92110          1        1   \n\n            month  year  dayofyear  dayofmonth  weekofyear  \nDate                                                        \n2020-01-02      1  2020          2           2           1  \n2020-01-03      1  2020          3           3           1  \n2020-01-06      1  2020          6           6           2  \n2020-01-07      1  2020          7           7           2  \n2020-01-08      1  2020          8           8           2  \n2020-01-09      1  2020          9           9           2  \n2020-01-10      1  2020         10          10           2  \n2020-01-13      1  2020         13          13           3  \n2020-01-14      1  2020         14          14           3  \n2020-01-15      1  2020         15          15           3  \n2020-01-16      1  2020         16          16           3  \n2020-01-17      1  2020         17          17           3  \n2020-01-21      1  2020         21          21           4  \n2020-01-22      1  2020         22          22           4  \n2020-01-23      1  2020         23          23           4  \n2020-01-24      1  2020         24          24           4  \n2020-01-27      1  2020         27          27           5  \n2020-01-28      1  2020         28          28           5  \n2020-01-29      1  2020         29          29           5  \n2020-01-30      1  2020         30          30           5  \n2020-01-31      1  2020         31          31           5  \n2020-02-02      2  2020         33           2           5  \n2020-02-03      2  2020         34           3           6  \n2020-02-04      2  2020         35           4           6  \n\n[24 rows x 28 columns]"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "x_train = sc.fit_transform(x)\n",
    "\n",
    "x_test = sc.transform(df_test.loc[:,features])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def build_timeseries(mat, y_col_index):\n",
    "    # y_col_index is the index of column that would act as output column\n",
    "    # total number of time-series samples would be len(mat) - TIME_STEPS\n",
    "    dim_0 = mat.shape[0] - TIME_STEPS\n",
    "    dim_1 = mat.shape[1]\n",
    "    x = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
    "    y = np.zeros((dim_0,))\n",
    "    \n",
    "    for i in tqdm_notebook(range(dim_0)):\n",
    "        x[i] = mat[i:TIME_STEPS+i]\n",
    "        y[i] = mat[TIME_STEPS+i, y_col_index]\n",
    "    print(\"length of time-series i/o\",x.shape,y.shape)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def trim_dataset(mat, batch_size):\n",
    "    \"\"\"\n",
    "    trims dataset to a size that's divisible by BATCH_SIZE\n",
    "    \"\"\"\n",
    "    no_of_rows_drop = mat.shape[0]%batch_size\n",
    "    if(no_of_rows_drop > 0):\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/anaconda3/envs/mlcourse/lib/python3.7/site-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  # This is added back by InteractiveShellApp.init_path()\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0ded73962a4c56be41ae15749dcd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=489.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nlength of time-series i/o (489, 10, 1) (489,)\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95de02b6efde4e25b7d22a5bb8cf0ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nlength of time-series i/o (14, 10, 1) (14,)\n"
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "TIME_STEPS = 10\n",
    "x_t, y_t = build_timeseries(x_train, 0)\n",
    "x_t = trim_dataset(x_t, BATCH_SIZE)\n",
    "y_t = trim_dataset(y_t, BATCH_SIZE)\n",
    "x_temp, y_temp = build_timeseries(x_test, 0)\n",
    "x_val, x_test_t = np.split(trim_dataset(x_temp, BATCH_SIZE),2)\n",
    "y_val, y_test_t = np.split(trim_dataset(y_temp, BATCH_SIZE),2)\n",
    "\n",
    "print(\"Test size\", x_test_t.shape, y_test_t.shape, x_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.1\n",
    "# lstm_model = Sequential()\n",
    "# lstm_model.add(LSTM(100, batch_input_shape=(BATCH_SIZE, TIME_STEPS, x_t.shape[2]), dropout=0.0, recurrent_dropout=0.0, stateful=True,     kernel_initializer='random_uniform'))\n",
    "# lstm_model.add(Dropout(0.5))\n",
    "# lstm_model.add(Dense(20,activation='relu'))\n",
    "# lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "# optimizer = optimizers.RMSprop(lr=lr)\n",
    "# lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "def create_model():\n",
    "    lstm_model = Sequential()\n",
    "    # (batch_size, timesteps, data_dim)\n",
    "    lstm_model.add(LSTM(100, batch_input_shape=(BATCH_SIZE, TIME_STEPS, x_t.shape[2]),\n",
    "                        dropout=0.0, recurrent_dropout=0.0, stateful=True, return_sequences=True,\n",
    "                        kernel_initializer='random_uniform'))\n",
    "    lstm_model.add(Dropout(0.4))\n",
    "    lstm_model.add(LSTM(60, dropout=0.0))\n",
    "    lstm_model.add(Dropout(0.4))\n",
    "    lstm_model.add(Dense(20,activation='relu'))\n",
    "    lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "    optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
    "    # optimizer = optimizers.SGD(lr=0.000001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return lstm_model\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1], 1)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=50,return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=50,return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=50))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(units=1))\n",
    "# model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "# model.fit(X_train,y_train,epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "try:\n",
    "    model = pickle.load(open(\"lstm_model\", 'rb'))\n",
    "    print(\"Loaded saved model...\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Model not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_update_model = True\n",
    "if model is None or is_update_model:\n",
    "    from keras import backend as K\n",
    "    print(\"Building model...\")\n",
    "    print(\"checking if GPU available\", K.tensorflow_backend._get_available_gpus())\n",
    "    model = create_model()\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                       patience=40, min_delta=0.0001)\n",
    "    \n",
    "    mcp = ModelCheckpoint(os.path.join(OUTPUT_PATH,\n",
    "                          \"best_model.h5\"), monitor='val_loss', verbose=1,\n",
    "                          save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "\n",
    "    # Not used here. But leaving it here as a reminder for future\n",
    "    r_lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=30, \n",
    "                                  verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    \n",
    "    csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'training_log_' + time.ctime().replace(\" \",\"_\") + '.log'), append=True)\n",
    "    \n",
    "    history = model.fit(x_t, y_t, epochs=params[\"epochs\"], verbose=2, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, validation_data=(trim_dataset(x_val, BATCH_SIZE),\n",
    "                        trim_dataset(y_val, BATCH_SIZE)), callbacks=[es, mcp, csv_logger])\n",
    "    \n",
    "    print(\"saving model...\")\n",
    "    modDate = str(fin_df_train[\"Date\"].iloc[-1].strftime('%Y-%m-%d'))\n",
    "    fileName = \"LSTM_Model_\"+modDate+\".sav\"\n",
    "    pickle.dump(model, open(fileName, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /anaconda3/envs/mlcourse/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 485 samples, validate on 5 samples\nEpoch 1/100\n - 1s - loss: 0.2875 - val_loss: 0.3662\nEpoch 2/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 3/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 4/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 5/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 6/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 7/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 8/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 9/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 10/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 11/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 12/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 13/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 14/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 15/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 16/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 17/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 18/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 19/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 20/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 21/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 22/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 23/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 24/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 25/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 26/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 27/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 28/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 29/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 30/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 31/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 32/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 33/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 34/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 35/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 36/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 37/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 38/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 39/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 40/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 41/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 42/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 43/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 44/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 45/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 46/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 47/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 48/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 49/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 50/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 51/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 52/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 53/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 54/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 55/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 56/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 57/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 58/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 59/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 60/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 61/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 62/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 63/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 64/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 65/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 66/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 67/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 68/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 69/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 70/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 71/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 72/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 73/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 74/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 75/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 76/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 77/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 78/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 79/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 80/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 81/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 82/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 83/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 84/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 85/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 86/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 87/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 88/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 89/100\n - 0s - loss: 0.2892 - val_loss: 0.3662\nEpoch 90/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 91/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 92/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 93/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 94/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 95/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 96/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 97/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 98/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 99/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\nEpoch 100/100\n - 1s - loss: 0.2892 - val_loss: 0.3662\n"
    }
   ],
   "source": [
    "# OUTPUT_PATH = \"/Users/qw19176/Documents/Courses/Team-Cpp/\"\n",
    "# csv_logger = CSVLogger(os.path.join(OUTPUT_PATH, 'LSTMRegressor' + '.log'), append=True)\n",
    "# epochs = 100\n",
    "# history = lstm_model.fit(x_t, y_t, epochs=epochs, verbose=2, batch_size=BATCH_SIZE,\n",
    "#                     shuffle=False, validation_data=(trim_dataset(x_val, BATCH_SIZE),\n",
    "#                     trim_dataset(y_val, BATCH_SIZE)), callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    \"batch_size\": [20, 30, 40],\n",
    "    \"time_steps\": [30, 60, 90], \n",
    "    \"lr\": [0.01, 0.001, 0.0001],\n",
    "    \"epochs\": [30, 50, 70]\n",
    "}\n",
    "\n",
    "def eval_model():\n",
    "    \"\"\"\n",
    "    implement your logic to build a model, train it and then calculate validation loss.\n",
    "    Save this validation loss using CSVLogger of Keras or in a text file. Later you can\n",
    "    query to get the best combination.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def get_all_combinations(params):\n",
    "    all_names = params.keys()\n",
    "    combinations = it.product(*(params[name] for name in all_names))\n",
    "    return list(combinations)\n",
    "\n",
    "def run_search(mat, params):\n",
    "    param_combs = get_all_combinations(params) # list of tuples\n",
    "    logging.info(\"Total combinations to try = {}\".format(len(param_combs)))\n",
    "    for i, combination in enumerate(param_combs):\n",
    "        logging.info(\"Trying combo no. {} {}\".format(i, combination))\n",
    "        eval_model(mat, combination, i)\n",
    "\n",
    "run_search(x_input, search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TALOS OPTIMISATION\n",
    "\"\"\"\n",
    "\n",
    "def data(search_params):\n",
    "    \"\"\"\n",
    "    The function that prepares the data for LSTM training specific to this problem as per values in search_params.\n",
    "    \"\"\"\n",
    "    global mat\n",
    "\n",
    "    BATCH_SIZE = search_params[\"batch_size\"]\n",
    "    TIME_STEPS = search_params[\"time_steps\"]\n",
    "    x_train, x_test = train_test_split(mat, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # scale the train and test dataset\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_train = min_max_scaler.fit_transform(x_train)\n",
    "    x_test = min_max_scaler.transform(x_test)\n",
    "\n",
    "    x_train_ts, y_train_ts = build_timeseries(x_train, 3, TIME_STEPS)\n",
    "    x_test_ts, y_test_ts = build_timeseries(x_test, 3, TIME_STEPS)\n",
    "    x_train_ts = trim_dataset(x_train_ts, BATCH_SIZE)\n",
    "    y_train_ts = trim_dataset(y_train_ts, BATCH_SIZE)\n",
    "    x_test_ts = trim_dataset(x_test_ts, BATCH_SIZE)\n",
    "    y_test_ts = trim_dataset(y_test_ts, BATCH_SIZE)\n",
    "    print(\"Test size(trimmed) {}, {}\".format(x_test_ts.shape, y_test_ts.shape))\n",
    "    return x_train_ts, y_train_ts, x_test_ts, y_test_ts\n",
    "  \n",
    "  def create_model_talos(x_train_ts, y_train_ts, x_test_ts, y_test_ts, params):\n",
    "    \"\"\"\n",
    "    function that builds model, trains, evaluates on validation data and returns Keras history object and model for\n",
    "    talos scanning. Here I am creating data inside function because data preparation varies as per the selected value of \n",
    "    batch_size and time_steps during searching. So we ignore data that's received here as argument from scan method of Talos.\n",
    "    \"\"\"\n",
    "    x_train_ts, y_train_ts, x_test_ts, y_test_ts = data(params)\n",
    "    BATCH_SIZE = params[\"batch_size\"]\n",
    "    TIME_STEPS = params[\"time_steps\"]\n",
    "    lstm_model = Sequential()\n",
    "    # (batch_size, timesteps, data_dim)\n",
    "    lstm_model.add(LSTM(params[\"lstm1_nodes\"], batch_input_shape=(BATCH_SIZE, TIME_STEPS, x_train_ts.shape[2]), dropout=0.2,\n",
    "                        recurrent_dropout=0.2, stateful=True, return_sequences=True,\n",
    "                        kernel_initializer='random_uniform'))\n",
    "    if params[\"lstm_layers\"] == 2:\n",
    "        lstm_model.add(LSTM(params[\"lstm2_nodes\"], dropout=0.2))\n",
    "    else:\n",
    "        lstm_model.add(Flatten())\n",
    "\n",
    "    if params[\"dense_layers\"] == 2:\n",
    "        lstm_model.add(Dense(params[\"dense2_nodes\"], activation='relu'))\n",
    "\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "    if params[\"optimizer\"] == 'rms':\n",
    "        optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
    "    else:\n",
    "        optimizer = optimizers.SGD(lr=params[\"lr\"], decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)  # binary_crossentropy\n",
    "    history = lstm_model.fit(x_train_ts, y_train_ts, epochs=params[\"epochs\"], verbose=2, batch_size=BATCH_SIZE,\n",
    "                             validation_data=[x_test_ts, y_test_ts],\n",
    "                             callbacks=[LogMetrics(search_params, params, -1), csv_logger])\n",
    "    return history, lstm_model\n",
    "  \n",
    "print(\"Starting Talos scanning...\")\n",
    "t = ta.Scan(x=mat, # data parameter is ignored in this example as here data varies based on batch_size & time_steps\n",
    "            y=mat[:,0], # dummy data just to avoid errors. input and output calculated in create_model_talos\n",
    "            model=create_model_talos,\n",
    "            params=search_params,\n",
    "            dataset_name='stock_ge',\n",
    "            experiment_no='1',\n",
    "            reduction_interval=10)\n",
    "\n",
    "pickle.dump(t, open(os.path.join(OUTPUT_PATH,\"talos_res\"),\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"easy\", \"easter\", \"eastmas\", \"estover\"]\n",
    "nonShiftFeatures = [\"easy\", \"easter\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['eastmas', 'estover']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f in nonShiftFeatures:\n",
    "    features.remove(f)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}